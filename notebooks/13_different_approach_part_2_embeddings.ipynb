{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2421726",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U sentence-transformers\n",
    "# https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ef85fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from etf_transformations import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b86d3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_data = pd.read_csv(\"../data/preprocessed/separate_stocks_finbert.csv\")\n",
    "base_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a643d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_data2 = pd.read_parquet(\"../data/preprocessed/separate_stocks_finbert.parquet\")\n",
    "base_data2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3cb272",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_data['row_id'] = base_data.index\n",
    "base_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ae7b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09be934",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2695e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mini test from the transformers website\n",
    "\n",
    "sentences = [\"This is an example sentence\", \"Each sentence is converted\"]\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(sentences)\n",
    "print(embeddings, embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a7fcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = base_data[\"Headlines\"].astype(str).tolist()\n",
    "\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "embeddings = model.encode(\n",
    "    sentences,\n",
    "    batch_size=64,\n",
    "    show_progress_bar=True,\n",
    "    convert_to_numpy=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a631c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_as_df = pd.DataFrame(embeddings, columns=[f\"emb_{i}\" for i in range(embeddings.shape[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9feb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_as_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabe7ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "i, j = 0,1  # indeksy w df\n",
    "\n",
    "v1 = embeddings_as_df.loc[i, [c for c in embeddings_as_df.columns if c.startswith(\"emb_\")]].values.reshape(1, -1)\n",
    "v2 = embeddings_as_df.loc[j, [c for c in embeddings_as_df.columns if c.startswith(\"emb_\")]].values.reshape(1, -1)\n",
    "\n",
    "cosine_similarity(v1, v2)[0, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96f3afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_as_df[\"row_id\"] = base_data[\"row_id\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f261012e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TU WTEDY TRZEBA ZROBIC MERGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cbf749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIDENCE DISTRIBUTION\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "conf = base_data[\"finbert_confidence\"].astype(float)\n",
    "\n",
    "print(\"N rows:\", len(base_data))\n",
    "print(\"NaNs in finbert_confidence:\", conf.isna().sum(), f\"({conf.isna().mean():.2%})\")\n",
    "print(\"Describe:\")\n",
    "print(conf.describe())\n",
    "\n",
    "print(\"Quantiles:\")\n",
    "print(conf.quantile([0.01, 0.05, 0.10, 0.25, 0.50, 0.75, 0.90, 0.95, 0.99]))\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(conf.dropna().values, bins=50)\n",
    "plt.title(\"finbert_confidence distribution\")\n",
    "plt.xlabel(\"finbert_confidence\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.show()\n",
    "\n",
    "sector_cols = [c for c in [\"XLE\",\"XLF\",\"XLK\",\"XLV\",\"XLY\"] if c in base_data.columns]\n",
    "\n",
    "for s in sector_cols:\n",
    "    c = base_data.loc[base_data[s] == 1, \"finbert_confidence\"].astype(float)\n",
    "    if len(c.dropna()) == 0:\n",
    "        print(f\"\\n{s}: no non-NaN confidence values\")\n",
    "        continue\n",
    "\n",
    "    print(f\"{s}\")\n",
    "    print(\"N headlines:\", len(c), \" NaNs:\", c.isna().sum())\n",
    "    print(\"Describe:\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
